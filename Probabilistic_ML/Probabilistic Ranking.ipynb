{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import scipy as s\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranking systems have many different applications, however most common ones are poor as they rely on arbitrary conventions which lead to poor proformance. In general, they try to answer they question **What is the probability that player 1 defeats player 2?**. In order to determine this probabilistically, there are a number of things to consider:\n",
    "\n",
    "- Considers who you played against.\n",
    "- Must be robust against players who have not played against eachother.\n",
    "- Give a good estimate at any point in the season.\n",
    "- Take into account performance inconsistancy.\n",
    "\n",
    "Therefore, what we want to infer is the player's **skill**, $w$. These skills must be comparable (i.e. a player with a higher skill must be more likely to win), and as such we want to do a probabilstic inference of a player's skill and be able to compute the probability of a game's outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A generative model for skill\n",
    "\n",
    "A summary of a generative model for game outcomes can be defined as:\n",
    "\n",
    "1. **Skills** Take two players with known skills, $$w_i \\in \\mathbb{R}$$\n",
    "2. **Skill Difference**: $$s = w_1 - w_2$$\n",
    "3. **Performance Difference**: Add noise ($n \\sim \\mathcal{N}(0, 1))$ to account for performance inconsistance: $$t = s + n$$\n",
    "4. **Game outcome** is given by $y=sign(t)$:\n",
    "    - $y = +1$ means player 1 wins\n",
    "    - $y = -1$ means player 2 wins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![FactorGraph](Figures/FactorGraph.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The probability of a player winning given their skills\n",
    "    \n",
    "Therefore we can work out the probability that player 1 wins given the players skills':\n",
    "\n",
    "$$p(y| w_1, w_2) = \\int \\int p(y|t) p(t|s) p(s | w_1, w_2) $$\n",
    "$$ = \\int p(y|t) p(t|w_1, w_2) dt$$\n",
    "$$ = \\int^{+\\infty}_{-\\infty} \\delta(y - sign(t)) \\mathcal{N}(t; w_1 - w_2, 1) dt$$\n",
    "$$ = \\int^{+\\infty}_{-\\infty} \\delta(1 - sign(yt)) \\mathcal{N}(yt; y(w_1 - w_2), 1) dt $$\n",
    "set z = yt and note the change in limits and dt:\n",
    "$$ = \\int^{+y\\infty}_{-y\\infty} \\delta(1 - sign(z)) \\mathcal{N}(z; y(w_1 - w_2), 1) y dz $$\n",
    "$$ = \\int^{+\\infty}_{-\\infty} \\delta(1 -sign(z)) \\mathcal{N}(z; y(w_1 - w_2), 1) dz $$\n",
    "And rearrange the limits:\n",
    "$$ = \\int^{+\\infty}_{0} \\mathcal{N}(z; y(w_1 - w_2), 1) dz $$\n",
    "using $x = y(w_1-w_2) - z$\n",
    "$$ = \\int^{y(w_1 - w_2)}_{-\\infty} \\mathcal{N}(x; 0, 1) dx $$\n",
    "$$ = \\Phi(y(w_1 - w_2))$$\n",
    "\n",
    "where $\\Phi(a)$ is the gaussian c.d.f, or the *probit* function.\n",
    "\n",
    "For the probability of player 1 winning, we simply use $p(y=1| w_1, w_2) = p(t>0| w_1, w_2) = \\Phi(w_1 - w_2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![PerformanceDifference](Figures/PerformanceDifference.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the skills (the posterior)\n",
    "\n",
    "$$p(w_1, w_2 | y) = \\frac{Priors \\times Likelihood}{Evidence}$$\n",
    "<br>\n",
    "$$ = \\frac{p(w_1)p(w_2) \\times p(y|w_1, w_2)}{\\int \\int p(w_1)p(w_2) \\times p(y|w_1, w_2) dw_1 dw_2}$$\n",
    "<br>\n",
    "$$ = \\frac{\\mathcal{N}(w_1; \\mu_1, \\sigma_1^2) \\mathcal{N}(w_2; \\mu_2, \\sigma_2^2) \\times \\Phi(y(w_1 - w_2))}{\\int \\int \\mathcal{N}(w_1; \\mu_1, \\sigma_1^2) \\mathcal{N}(w_2; \\mu_2, \\sigma_2^2) \\times \\Phi(y(w_1 - w_2)) dw_1 dw_2}$$\n",
    "\n",
    "The joint posterior over skills does not have a closed form as the probit function is not closed. Additionally, $w_1$ and $w_2$ have become correlated due to the priors and therefore does not factorise, nor is it a gaussian density function.\n",
    "\n",
    "Fortunately, the evidence does have a closed form:\n",
    "\n",
    "$$p(y) = \\int \\int \\mathcal{N}(w_1; \\mu_1, \\sigma_1^2) \\mathcal{N}(w_2; \\mu_2, \\sigma_2^2) \\times \\Phi(y(w_1 - w_2)) dw_1 dw_2 = \\Phi \\bigg(\\frac{y(\\mu_1 - \\mu_2)}{\\sqrt{1 + \\sigma_1^2 + \\sigma_2^2}} \\bigg)$$\n",
    "\n",
    "This is effectively a smoother version of the likelihood as we are using mean skills of each player, and normalising over their variances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "mat = scipy.io.loadmat('tennis_data.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rafael-Nadal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Juan-Monaco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Juan-Martin-Del-Potro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mardy-Fish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Roger-Federer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    name\n",
       "0           Rafael-Nadal\n",
       "1            Juan-Monaco\n",
       "2  Juan-Martin-Del-Potro\n",
       "3             Mardy-Fish\n",
       "4          Roger-Federer"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winner</th>\n",
       "      <th>loser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   winner  loser\n",
       "0       1      2\n",
       "1       1      3\n",
       "2       1      3\n",
       "3       1      3\n",
       "4       1      3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PLAYERS = pd.DataFrame(mat['W'], columns=['name']).applymap(lambda x: x[0])  # remove the list around each players name\n",
    "GAMES = pd.DataFrame(mat['G'], columns=['winner', 'loser'])\n",
    "display(PLAYERS.head(), GAMES.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gibbs Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration of an Intractable Posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basis of Monte-Carlo approximation is:\n",
    "$$\\mathbb{E}_{p(x)} \\big[ \\Phi(x) \\big] \\approx \\hat{\\Phi} = \\frac{1}{T} \\sum^t_{\\tau = 1} \\Phi(x^{(\\tau)}), \\text{  where } x^{(\\tau)} \\sim p(x)$$\n",
    "\n",
    "Note that $x^{(\\tau)}$ is the $\\tau$th d-dimensional sample from the distribution p(x), which is analytically intractable (and typically d>>1).\n",
    "\n",
    "This is infact an unbiased estimate, with $Var[\\hat{\\Phi}] = \\frac{Var[\\Phi]}{T}$. Note $Var[\\Phi] = \\int (\\Phi(x) - \\mathbb{E}[\\Phi])^2 p(x) dx$. Note that this is independent of dimension d, of x.\n",
    "\n",
    "\n",
    "How do we generate samples from p(x)? If the distribution has a standard form then we could generate independent samples, however, it is often difficult to sample from this joint distribution if it is within a high dimensional space (the curse of dimensionality). In order to get around this we can use **Gibbs Sampling**, which uses a Markov Chain to generate dependent samples from the desired distribution:\n",
    "\n",
    "$$x_i' \\sim  p(x_i | x_{1, 2, ..., i-1, i+1, ..., d})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gibbs Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In gibbs sampling, we sample from the proposal distribution, and keep a record of the current state, $x_i$, and the proposal distribution, $q(x^\\tau|x^{\\tau-1})$. There are several requirements upon this distribution:\n",
    "\n",
    "1. The markov chain must sample from a known distribution\n",
    "1. For $\\tau \\rightarrow \\infty$, the distribution $p(x^{(\\tau)})$ converges to the required distribution, $p^*(x)$, irrespective of the choice of initial distribution i.e. the markov chain must be ergodic.\n",
    "1. !!!\n",
    "\n",
    "Consider the distribution $p(x) = p(x_{1:d})$. The gibbs sampling algorithm is as follows:\n",
    "\n",
    "\n",
    "> 1. Initialise $\\{x_i : i = 1, .., d\\}$\n",
    "> 2. For $\\tau = 1, ..., T$: <br>\n",
    "    > &nbsp;&nbsp;&nbsp;&nbsp; For $i = 1, ..., d$: <br>\n",
    "        > &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Sample $x_{i}^{\\tau+1} \\sim p(x_i|x_{\\backslash i}^{(\\tau)})$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![GibbsSampling](Figures/GibbsSampling.jpg)\n",
    "\n",
    "Above is an illustration of Gibbs sampmling by alternate updates of two variables, whose distribution is a correlated GAussian. The step size is govened by the standard deviation of the  <span style=\"color:green\">condiditional distribution</span>, and is O(l), leading to slow progression in the direction of elongation of the <span style=\"color:red\">joint distribution</span>. The number of steps needed to obtain an independent sample from the distribution is $O((\\frac{L}{l})^2)$. I.e. **Strong correlations slow down gibbs sampling**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "todo. \n",
    "1. Read the gibbs section of Pattern Recog and add anything from there into here\n",
    "1. Reread the notes and add the specific maths\n",
    "1. implement the gibbs sampling algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\left(\\begin{array}{cc} \n",
    "0.8944272 & 0.4472136\\\\\n",
    "-0.4472136 & -0.8944272\n",
    "\\end{array}\\right)\n",
    "\\left(\\begin{array}{cc} \n",
    "10 & 0\\\\ \n",
    "0 & 5\n",
    "\\end{array}\\right)\n",
    "$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_distribution(x, mu, s):\n",
    "    exponent = -0.5*((x-mu)/s)**2\n",
    "    Z = (s * np.sqrt(2*np.pi))\n",
    "    return np.exp(exponent) / Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs_sampler(total_iters, players=PLAYERS, games=GAMES):\n",
    "     skills_container = np.zeros(len(), total_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
